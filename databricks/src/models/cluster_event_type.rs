/*
 * Jobs API 2.1
 *
 * The Jobs API allows you to create, edit, and delete jobs.
 *
 * The version of the OpenAPI document: 2.1
 * 
 * Generated by: https://openapi-generator.tech
 */

/// ClusterEventType : * `CREATING`: Indicates that the cluster is being created. * `DID_NOT_EXPAND_DISK`: Indicates that a disk is low on space, but adding disks would put it over the max capacity. * `EXPANDED_DISK`: Indicates that a disk was low on space and the disks were expanded. * `FAILED_TO_EXPAND_DISK`: Indicates that a disk was low on space and disk space could not be expanded. * `INIT_SCRIPTS_STARTING`: Indicates that the cluster scoped init script has started. * `INIT_SCRIPTS_FINISHED`: Indicates that the cluster scoped init script has finished. * `STARTING`: Indicates that the cluster is being started. * `RESTARTING`: Indicates that the cluster is being started. * `TERMINATING`: Indicates that the cluster is being terminated. * `EDITED`: Indicates that the cluster has been edited. * `RUNNING`: Indicates the cluster has finished being created. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `RESIZING`: Indicates a change in the target size of the cluster (upsize or downsize). * `UPSIZE_COMPLETED`: Indicates that nodes finished being added to the cluster. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `NODES_LOST`: Indicates that some nodes were lost from the cluster. * `DRIVER_HEALTHY`: Indicates that the driver is healthy and the cluster is ready for use. * `DRIVER_UNAVAILABLE`: Indicates that the driver is unavailable. * `SPARK_EXCEPTION`: Indicates that a Spark exception was thrown from the driver. * `DRIVER_NOT_RESPONDING`: Indicates that the driver is up but is not responsive, likely due to GC. * `DBFS_DOWN`: Indicates that the driver is up but DBFS is down. * `METASTORE_DOWN`: Indicates that the driver is up but the metastore is down. * `NODE_BLACKLISTED`: Indicates that a node is not allowed by Spark. * `PINNED`: Indicates that the cluster was pinned. * `UNPINNED`: Indicates that the cluster was unpinned.

/// * `CREATING`: Indicates that the cluster is being created. * `DID_NOT_EXPAND_DISK`: Indicates that a disk is low on space, but adding disks would put it over the max capacity. * `EXPANDED_DISK`: Indicates that a disk was low on space and the disks were expanded. * `FAILED_TO_EXPAND_DISK`: Indicates that a disk was low on space and disk space could not be expanded. * `INIT_SCRIPTS_STARTING`: Indicates that the cluster scoped init script has started. * `INIT_SCRIPTS_FINISHED`: Indicates that the cluster scoped init script has finished. * `STARTING`: Indicates that the cluster is being started. * `RESTARTING`: Indicates that the cluster is being started. * `TERMINATING`: Indicates that the cluster is being terminated. * `EDITED`: Indicates that the cluster has been edited. * `RUNNING`: Indicates the cluster has finished being created. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `RESIZING`: Indicates a change in the target size of the cluster (upsize or downsize). * `UPSIZE_COMPLETED`: Indicates that nodes finished being added to the cluster. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `NODES_LOST`: Indicates that some nodes were lost from the cluster. * `DRIVER_HEALTHY`: Indicates that the driver is healthy and the cluster is ready for use. * `DRIVER_UNAVAILABLE`: Indicates that the driver is unavailable. * `SPARK_EXCEPTION`: Indicates that a Spark exception was thrown from the driver. * `DRIVER_NOT_RESPONDING`: Indicates that the driver is up but is not responsive, likely due to GC. * `DBFS_DOWN`: Indicates that the driver is up but DBFS is down. * `METASTORE_DOWN`: Indicates that the driver is up but the metastore is down. * `NODE_BLACKLISTED`: Indicates that a node is not allowed by Spark. * `PINNED`: Indicates that the cluster was pinned. * `UNPINNED`: Indicates that the cluster was unpinned.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum ClusterEventType {
    #[serde(rename = "CREATING")]
    CREATING,
    #[serde(rename = "DID_NOT_EXPAND_DISK")]
    DIDNOTEXPANDDISK,
    #[serde(rename = "EXPANDED_DISK")]
    EXPANDEDDISK,
    #[serde(rename = "FAILED_TO_EXPAND_DISK")]
    FAILEDTOEXPANDDISK,
    #[serde(rename = "INIT_SCRIPTS_STARTING")]
    INITSCRIPTSSTARTING,
    #[serde(rename = "INIT_SCRIPTS_FINISHED")]
    INITSCRIPTSFINISHED,
    #[serde(rename = "STARTING")]
    STARTING,
    #[serde(rename = "RESTARTING")]
    RESTARTING,
    #[serde(rename = "TERMINATING")]
    TERMINATING,
    #[serde(rename = "EDITED")]
    EDITED,
    #[serde(rename = "RUNNING")]
    RUNNING,
    #[serde(rename = "RESIZING")]
    RESIZING,
    #[serde(rename = "UPSIZE_COMPLETED")]
    UPSIZECOMPLETED,
    #[serde(rename = "NODES_LOST")]
    NODESLOST,
    #[serde(rename = "DRIVER_HEALTHY")]
    DRIVERHEALTHY,
    #[serde(rename = "DRIVER_UNAVAILABLE")]
    DRIVERUNAVAILABLE,
    #[serde(rename = "SPARK_EXCEPTION")]
    SPARKEXCEPTION,
    #[serde(rename = "DRIVER_NOT_RESPONDING")]
    DRIVERNOTRESPONDING,
    #[serde(rename = "DBFS_DOWN")]
    DBFSDOWN,
    #[serde(rename = "METASTORE_DOWN")]
    METASTOREDOWN,
    #[serde(rename = "NODE_BLACKLISTED")]
    NODEBLACKLISTED,
    #[serde(rename = "PINNED")]
    PINNED,
    #[serde(rename = "UNPINNED")]
    UNPINNED,

}

impl ToString for ClusterEventType {
    fn to_string(&self) -> String {
        match self {
            Self::CREATING => String::from("CREATING"),
            Self::DIDNOTEXPANDDISK => String::from("DID_NOT_EXPAND_DISK"),
            Self::EXPANDEDDISK => String::from("EXPANDED_DISK"),
            Self::FAILEDTOEXPANDDISK => String::from("FAILED_TO_EXPAND_DISK"),
            Self::INITSCRIPTSSTARTING => String::from("INIT_SCRIPTS_STARTING"),
            Self::INITSCRIPTSFINISHED => String::from("INIT_SCRIPTS_FINISHED"),
            Self::STARTING => String::from("STARTING"),
            Self::RESTARTING => String::from("RESTARTING"),
            Self::TERMINATING => String::from("TERMINATING"),
            Self::EDITED => String::from("EDITED"),
            Self::RUNNING => String::from("RUNNING"),
            Self::RESIZING => String::from("RESIZING"),
            Self::UPSIZECOMPLETED => String::from("UPSIZE_COMPLETED"),
            Self::NODESLOST => String::from("NODES_LOST"),
            Self::DRIVERHEALTHY => String::from("DRIVER_HEALTHY"),
            Self::DRIVERUNAVAILABLE => String::from("DRIVER_UNAVAILABLE"),
            Self::SPARKEXCEPTION => String::from("SPARK_EXCEPTION"),
            Self::DRIVERNOTRESPONDING => String::from("DRIVER_NOT_RESPONDING"),
            Self::DBFSDOWN => String::from("DBFS_DOWN"),
            Self::METASTOREDOWN => String::from("METASTORE_DOWN"),
            Self::NODEBLACKLISTED => String::from("NODE_BLACKLISTED"),
            Self::PINNED => String::from("PINNED"),
            Self::UNPINNED => String::from("UNPINNED"),
        }
    }
}

impl Default for ClusterEventType {
    fn default() -> ClusterEventType {
        Self::CREATING
    }
}




